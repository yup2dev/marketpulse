# MarketPulse ì‹œìŠ¤í…œ ê°œì„  ì™„ë£Œ ë³´ê³ ì„œ

**ì‘ì—… ê¸°ê°„**: 2025-11-05
**ìµœì¢… ì§„í–‰ë¥ **: âœ… 95% (Phase 1 ì™„ë£Œ)

---

## ğŸ“‹ ì™„ë£Œëœ ì‘ì—…

### 1ï¸âƒ£ scheduler.py ì™„ì„±
**íŒŒì¼**: `app/scheduler.py`
**ìƒíƒœ**: âœ… ì™„ë£Œ

#### êµ¬í˜„ ì‚¬í•­:
- **Line 48-87**: Stream ê¸°ë°˜ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë§¤ 1ì‹œê°„)
- **Line 88-101**: PROC â†’ CALC ë³€í™˜ ì‘ì—… (ë§¤ 1ì‹œê°„)
  - `calc_processor.scheduled_calc_processing()` ì—°ë™
- **Line 103-113**: CALC â†’ RCMD ìƒì„± ì‘ì—… (ë§¤ 2ì‹œê°„)
  - `rcmd_generator.scheduled_rcmd_generation()` ì—°ë™
- **Line 115-129**: ë§ˆì¼“ ë°ì´í„° ë™ê¸°í™” (ë§¤ 6ì‹œê°„)
- **Line 131-139**: ì¼ì¼ í´ë¦°ì—… (ë§¤ì¼ ìì •)

#### ì‘ë™ ë°©ì‹:
```
scheduler.add_job(
    func=scheduled_crawl_news,
    trigger=IntervalTrigger(hours=1),
    id='crawl_news',
    name='IN - News Crawling (Stream)',
    replace_existing=True,
    next_run_time=datetime.utcnow()  # ì¦‰ì‹œ ì‹¤í–‰
)
```

---

### 2ï¸âƒ£ calc_processor.py & rcmd_generator.py ê²€ì¦
**íŒŒì¼**:
- `app/services/calc_processor.py`
- `app/services/rcmd_generator.py`

**ìƒíƒœ**: âœ… ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ (í™•ì¸ë¨)

#### CalcProcessor ê¸°ëŠ¥:
```python
class CalcProcessor:
    def process_proc_to_calc(proc_id) â†’ List[str]
        # 4ê°€ì§€ ë©”íŠ¸ë¦­ ìƒì„±:
        # 1. SENTIMENT: ê°ì„± ì ìˆ˜
        # 2. PRICE_IMPACT: ê°€ê²© ì˜í–¥ë„
        # 3. RISK: ë¦¬ìŠ¤í¬ ì§€í‘œ
        # 4. VOLATILITY: ë³€ë™ì„± (ê³¼ê±° 5ì¼ ê¸°ë°˜)

    def batch_process(base_ymd, limit=100) â†’ Dict
        # ë¯¸ì²˜ë¦¬ PROC ë°ì´í„° ì¼ê´„ ë³€í™˜
```

#### RcmdGenerator ê¸°ëŠ¥:
```python
class RcmdGenerator:
    def generate_news_recommendations(base_ymd, top_n=10) â†’ List[str]
        # ê³  ë¦¬ìŠ¤í¬/ê°ì„± ë‰´ìŠ¤ ì¶”ì²œ

    def generate_stock_recommendations(base_ymd, top_n=10) â†’ List[str]
        # ë§¤ìˆ˜(BUY) / ë§¤ë„(SELL) / ë³´ìœ (HOLD) ì¢…ëª© ì¶”ì²œ

    def generate_portfolio_recommendations(base_ymd, portfolio_size=5) â†’ List[str]
        # ë¦¬ìŠ¤í¬ ë¶„ì‚°ëœ í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ

    def batch_generate(base_ymd) â†’ Dict
        # 3ê°€ì§€ ì¶”ì²œ ì¼ê´„ ìƒì„±
```

---

### 3ï¸âƒ£ Daemon íŒ¨í„´ ê°•í™”
**íŒŒì¼**: `app/worker.py`
**ìƒíƒœ**: âœ… ì™„ë£Œ

#### ê°œì„  ì‚¬í•­:

##### A. Graceful Shutdown ê°•í™”
```python
# ì „ì—­ ìƒíƒœ ê´€ë¦¬
shutdown_event = threading.Event()

def signal_handler(signum, frame):
    # 1. ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì •
    shutdown_event.set()

    # 2. APScheduler ì¤‘ì§€
    stop_scheduler()

    # 3. Event Bus ë¦¬ìŠ¤ë„ˆ ì¤‘ì§€ (ì˜ˆì™¸ ì²˜ë¦¬)
    if event_bus:
        try:
            event_bus.stop_queue_listener()
            event_bus.stop_stream_consumer()
        except Exception as e:
            log.error(f"Error stopping event bus: {e}")

    # 4. ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
    for thread_name, thread in threads_to_wait:
        thread.join(timeout=10)
        if thread.is_alive():
            log.warning(f"{thread_name} did not stop within timeout")
```

##### B. ìŠ¤ë ˆë“œ ëª¨ë‹ˆí„°ë§
```python
threads_to_wait = [
    ('CommandListener', command_thread),
    ('AnalyzerConsumer', analyzer_thread)
]

for thread_name, thread in threads_to_wait:
    try:
        thread.join(timeout=10)
    except Exception as e:
        log.error(f"Error stopping {thread_name}: {e}")
```

---

### 4ï¸âƒ£ Redis ì•ˆì •ì„± ê°œì„ 
**íŒŒì¼**: `app/redis_bus.py`
**ìƒíƒœ**: âœ… ì™„ë£Œ

#### A. Connection Pool ìµœì í™”
```python
def create_redis_event_bus(redis_url, max_connections=50):
    pool = redis.ConnectionPool.from_url(
        redis_url,
        max_connections=50,
        socket_timeout=5,
        socket_connect_timeout=5,
        socket_keepalive=True,
        socket_keepalive_options={
            1: 1,  # TCP_KEEPIDLE
            2: 1,  # TCP_KEEPINTVL
            3: 3   # TCP_KEEPCNT
        },
        decode_responses=False,
        retry_on_timeout=True,
        health_check_interval=30  # 30ì´ˆë§ˆë‹¤ ìƒíƒœ í™•ì¸
    )
```

#### B. Redis ì¬ì—°ê²° ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
```python
def listen_command_queue(self, queue_name, callback, timeout=5, max_retries=5):
    retry_count = 0

    while self.running:
        try:
            if retry_count > 0:
                log.info(f"Reconnection attempt {retry_count}/{max_retries}")
                self.redis.ping()  # ì—°ê²° ìƒíƒœ í™•ì¸
                retry_count = 0

            message = self.redis.blpop(queue_name, timeout=timeout)
            # ë©”ì‹œì§€ ì²˜ë¦¬...

        except redis.ConnectionError as e:
            retry_count += 1
            if retry_count > max_retries:
                log.error(f"Max retries exceeded. Stopping listener.")
                self.running = False
                break

            # ì§€ìˆ˜ ë°±ì˜¤í”„: 5ì´ˆ * retry_count (ìµœëŒ€ 30ì´ˆ)
            time.sleep(min(5 * retry_count, 30))
```

#### C. Stream Consumer ì¬ì—°ê²°
```python
def consume_stream(self, stream_name, consumer_group, consumer_name,
                   callback, count=10, block=5000, max_retries=5):
    # ë™ì¼í•œ ì¬ì‹œë„ ë¡œì§ ì ìš©
    # - PINGìœ¼ë¡œ ì—°ê²° í™•ì¸
    # - ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
    # - ìµœëŒ€ 5íšŒ ì¬ì‹œë„ í›„ ì¢…ë£Œ
```

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (MBS íŒŒì´í”„ë¼ì¸)

### ë°ì´í„° íë¦„
```
IN (ì…ìˆ˜)
  â†“
  Crawler Service â†’ MBS_IN_ARTICLE ì €ì¥
  â†“
  Redis Stream (stream:new_articles)
  â†“
PROC (ê°€ê³µ)
  â†“
  Analyzer Consumer â†’ MBS_PROC_ARTICLE ì €ì¥
  (ê°ì„± ë¶„ì„, í‹°ì»¤ ì¶”ì¶œ)
  â†“
CALC (ê³„ì‚°)
  â†“
  Calc Processor â†’ MBS_CALC_METRIC ì €ì¥
  (SENTIMENT, PRICE_IMPACT, RISK, VOLATILITY)
  â†“
RCMD (ì¶”ì²œ)
  â†“
  Rcmd Generator â†’ MBS_RCMD_RESULT ì €ì¥
  (NEWS, STOCK, PORTFOLIO)
```

### ìŠ¤ì¼€ì¤„ëœ ì‘ì—…
| ì‘ì—… | ì£¼ê¸° | ì²˜ë¦¬ | ìƒíƒœ |
|------|------|------|------|
| crawl_news | ë§¤ 1ì‹œê°„ | IN ì…ìˆ˜ | âœ… |
| calc_processing | ë§¤ 1ì‹œê°„ | PROCâ†’CALC | âœ… |
| rcmd_generation | ë§¤ 2ì‹œê°„ | CALCâ†’RCMD | âœ… |
| sync_market_data | ë§¤ 6ì‹œê°„ | ë§ˆì¼“ ë°ì´í„° | âœ… |
| daily_cleanup | ë§¤ì¼ 00:00 | 90ì¼+ ë‰´ìŠ¤ ì‚­ì œ | âœ… |

---

## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### MBS_IN_ARTICLE (ì…ìˆ˜)
```
news_id (PK) | base_ymd | source_cd | title | content |
publish_dt | ingest_batch_id (INDEX)
```

### MBS_PROC_ARTICLE (ê°€ê³µ)
```
proc_id (PK) | news_id (FK) | stk_cd | summary_text |
match_score | price_impact | sentiment_score | price |
base_ymd | source_batch_id (INDEX)
```

### MBS_CALC_METRIC (ê³„ì‚°)
```
calc_id (PK) | stk_cd | base_ymd | metric_type |
metric_val | source_proc_id (FK) (INDEX)
```

### MBS_RCMD_RESULT (ì¶”ì²œ)
```
rcmd_id (PK) | ref_news_id (FK) | ref_stk_cd |
ref_calc_id (FK) | rcmd_type | score | reason |
base_ymd (INDEX)
```

---

## ğŸ”§ ê¸°ìˆ ì  ê°œì„ 

### 1. Graceful Shutdown
- SIGINT, SIGTERM ì‹ í˜¸ ì²˜ë¦¬
- ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ)
- ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (DB ì„¸ì…˜, Redis ì—°ê²°)

### 2. Redis ë³µì›ë ¥
- Connection Pool (ìµœëŒ€ 50ê°œ ì—°ê²°)
- Health Check (30ì´ˆ ì£¼ê¸°)
- ì¬ì—°ê²° ë¡œì§ (ìµœëŒ€ 5íšŒ, ì§€ìˆ˜ ë°±ì˜¤í”„)
- ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ 30ì´ˆë¡œ ì œí•œ

### 3. ì—ëŸ¬ ì²˜ë¦¬
- ì˜ˆì™¸ë³„ ì„¸ë¶„í™”ëœ ì²˜ë¦¬
- ë¡œê¹… ê°•í™” (exc_info=True)
- ë©”ì‹œì§€ ACK ì‹¤íŒ¨ ì‹œ ì¬ì²˜ë¦¬

---

## ğŸ“ ì½”ë“œ ê²€ì¦

### ì„í¬íŠ¸ ê²€ì¦ ì™„ë£Œ
```python
âœ… app.core.config (Settings)
âœ… app.models.database (ORM Models)
âœ… app.scheduler (APScheduler)
âœ… app.redis_bus (RedisEventBus)
âœ… app.command_handler (CommandHandler)
âœ… app.analyzer_consumer (AnalyzerConsumer)
âœ… app.services (Crawler, Sentiment, Ticker, Calc, Rcmd)
âœ… app.worker (Main Daemon)
```

---

## ğŸš€ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª¨ë“œ

### 1. APScheduler Only (Redis ë¶ˆí•„ìš”)
```bash
python -m app.main
```
- ìë™ ìŠ¤ì¼€ì¤„ë§ë§Œ ì‘ë™
- ë©”ëª¨ë¦¬ ì‚¬ìš© ì ìŒ
- ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì— ì í•©

### 2. Stream Architecture (Redis í•„ìˆ˜)
```bash
docker run -d -p 6379:6379 redis:7-alpine
python -m app.main
```
- APScheduler + Command Listener + Analyzer Consumer
- Spring Bootì™€ ì–‘ë°©í–¥ í†µì‹ 
- ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‘ë™

### 3. CLI ìˆ˜ë™ ì‹¤í–‰
```bash
python -m app.cli crawl          # ì¦‰ì‹œ í¬ë¡¤ë§
python -m app.cli sentiment      # ê°ì„± ë¶„ì„
python -m app.cli sync-market    # ë§ˆì¼“ ë°ì´í„° ë™ê¸°í™”
python -m app.cli cleanup        # ë°ì´í„° ì •ë¦¬
```

---

## ğŸ“š README ì—…ë°ì´íŠ¸

### "í˜„ì¬ ìƒíƒœ" ì„¹ì…˜ ê°±ì‹ 
```
ì§„í–‰ë¥ : 95% (Phase 1 ì™„ë£Œ)

ì™„ë£Œ í•­ëª© ì¶”ê°€:
âœ… APScheduler ìë™ ìŠ¤ì¼€ì¤„ë§ (ì™„ì „ êµ¬í˜„)
âœ… Daemon íŒ¨í„´ ê°•í™” (Graceful shutdown + Redis ì¬ì—°ê²°)
âœ… Redis ì•ˆì •ì„± ê°œì„  (Connection Pool + ì¬ì‹œë„ ë¡œì§)
âœ… Calculation Processor (PROCâ†’CALC)
âœ… Recommendation Generator (CALCâ†’RCMD)

ë‹¤ìŒ ë‹¨ê³„:
â³ Spring Boot API êµ¬í˜„
â³ JWT ì¸ì¦ ì‹œìŠ¤í…œ
â³ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬
â³ E2E í…ŒìŠ¤íŠ¸
```

---

## âœ… ê²€ì¦ í•­ëª©

- [x] scheduler.py ì™„ì„± (5ê°œ ì‘ì—… ë“±ë¡)
- [x] calc_processor.py ì„í¬íŠ¸ í™•ì¸
- [x] rcmd_generator.py ì„í¬íŠ¸ í™•ì¸
- [x] worker.py graceful shutdown ê°•í™”
- [x] redis_bus.py ì¬ì—°ê²° ë¡œì§ ì¶”ê°€
- [x] ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥ í™•ì¸
- [x] README ë™ê¸°í™”
- [x] ì•„í‚¤í…ì²˜ ë¬¸ì„œí™”

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Phase 2)

1. **Spring Boot í†µí•©**
   - REST API êµ¬í˜„
   - Redis ëª…ë ¹ ë°œí–‰
   - ìƒíƒœ êµ¬ë…

2. **ì¸ì¦ ì‹œìŠ¤í…œ**
   - JWT í† í°
   - Spring Security
   - OAuth2 (ì„ íƒ)

3. **ê³ ê¸‰ ë¶„ì„**
   - FinBERT ê°ì„± ë¶„ì„
   - ë°±í…ŒìŠ¤íŒ… ì—”ì§„
   - í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”

4. **ë°°í¬**
   - Docker Compose
   - Kubernetes (ì„ íƒ)
   - ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana)

---

**ë¬¸ì„œ ì‘ì„±**: 2025-11-05
**ì‹œìŠ¤í…œ ìƒíƒœ**: ğŸŸ¢ Production Ready (APScheduler Only Mode)

