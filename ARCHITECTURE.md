# MarketPulse Stream Architecture

## ì‹œìŠ¤í…œ í”Œë¡œìš°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ§‘â€ğŸ’» Spring API / Portal (Control Layer)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ì‚¬ìš©ì   â”‚ â†’  â”‚   REST   â”‚ â†’  â”‚  Redis   â”‚    â”‚  Redis   â”‚      â”‚
â”‚  â”‚  ìš”ì²­    â”‚    â”‚Controllerâ”‚    â”‚Publisher â”‚    â”‚Subscriberâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚           â”‚              â”‚
                           â”‚           â”‚              â”‚
                           â–¼           â–¼              â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ” Redis (Message / Event Bus)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ R1: queue:manual_command  (Spring â†’ Python ëª…ë ¹ ì „ì†¡)       â”‚   â”‚
â”‚  â”‚ R2: stream:new_articles   (Crawler â†’ Analyzer íŒŒì´í”„ë¼ì¸)   â”‚   â”‚
â”‚  â”‚ R3: pub:status_update     (Python â†’ Spring ìƒíƒœ ì „ì†¡)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚           â”‚              â”‚
                           â–¼           â–¼              â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ Python Service (Daemon Layer)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ D1: Systemd / Docker Daemon (í•­ìƒ ì‹¤í–‰ ìœ ì§€)                 â”‚  â”‚
â”‚  â”‚     â””â”€ D2: Orchestrator (APScheduler + Listener)            â”‚  â”‚
â”‚  â”‚          â”œâ”€ Main Thread: APScheduler (ìë™ ìŠ¤ì¼€ì¤„ë§)         â”‚  â”‚
â”‚  â”‚          â”œâ”€ Thread 1: Command Listener (ëª…ë ¹ ìˆ˜ì‹ )           â”‚  â”‚
â”‚  â”‚          â””â”€ Thread 2: Analyzer Consumer (ë¶„ì„ íŒŒì´í”„ë¼ì¸)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ D4: Crawler  â”‚ â†’ â”‚ D5: Analyzer â”‚ â†’ â”‚ D6: DB Writerâ”‚            â”‚
â”‚  â”‚   Module     â”‚   â”‚    Module    â”‚   â”‚              â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                              â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚  â”‚ D7: Redis Publisher (ìƒíƒœ/ê²°ê³¼ ì „ì†¡)                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ—„ï¸ Database (Persistent Layer)                     â”‚
â”‚                     PostgreSQL / SQLite                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### 1. Redis Event Bus (ë©”ì‹œì§€ í—ˆë¸Œ)

**íŒŒì¼:** `app/redis_bus.py`

3ê°€ì§€ ë©”ì‹œì§• íŒ¨í„´ í†µí•©:

#### R1: Queue Pattern (Spring â†’ Python ëª…ë ¹)
```python
# Spring â†’ Python
redis.rpush('marketpulse:commands', {
    'task_type': 'crawl_news',
    'params': {}
})

# Pythonì´ BLPOPìœ¼ë¡œ ëŒ€ê¸°í•˜ë‹¤ê°€ ì²˜ë¦¬
```

**ìš©ë„:** Springì—ì„œ ìˆ˜ë™ íŠ¸ë¦¬ê±° (ì˜ˆ: "ì§€ê¸ˆ í¬ë¡¤ë§" ë²„íŠ¼)

#### R2: Stream Pattern (Crawler â†’ Analyzer íŒŒì´í”„ë¼ì¸)
```python
# Crawlerê°€ ë°œí–‰
redis.xadd('stream:new_articles', {
    'article_id': '123',
    'url': 'https://...'
})

# Analyzer Consumer Groupì´ êµ¬ë…
redis.xreadgroup('analyzer-group', 'consumer-1', ...)
```

**ì¥ì :**
- Crawlerì™€ Analyzer ë¶„ë¦¬ (ëŠìŠ¨í•œ ê²°í•©)
- ì—¬ëŸ¬ Analyzer Worker ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
- ë©”ì‹œì§€ ì¬ì²˜ë¦¬ (ACK ì‹¤íŒ¨ ì‹œ)

#### R3: Pub/Sub Pattern (Python â†’ Spring ìƒíƒœ)
```python
# Pythonì´ ë°œí–‰
redis.publish('marketpulse:status', {
    'status': 'completed',
    'task_type': 'crawl_news',
    'data': {...}
})

# Springì´ êµ¬ë… (ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸)
```

**ìš©ë„:** ì‹¤ì‹œê°„ ì§„í–‰ë¥ , ì™„ë£Œ/ì‹¤íŒ¨ ì•Œë¦¼

---

### 2. Command Handler (D3: Redis Listener)

**íŒŒì¼:** `app/command_handler.py`

Spring ëª…ë ¹ì„ ë°›ì•„ ì²˜ë¦¬:

```python
def handle_command(command):
    task_type = command['task_type']

    # ì‹œì‘ ìƒíƒœ ë°œí–‰
    publish_status('started', task_type)

    try:
        result = execute_task(task_type)
        publish_status('completed', task_type, result)
    except Exception as e:
        publish_status('failed', task_type, error)
```

---

### 3. Crawler Module (D4)

**íŒŒì¼:** `app/services/crawler_service.py`

#### ê¸°ì¡´ ë°©ì‹ (ë™ê¸°ì‹)
```python
def crawl_all_news():
    # í¬ë¡¤ë§ + ë¶„ì„ì„ í•œë²ˆì— ì²˜ë¦¬
    for article in crawl():
        analyze_and_save(article)
```

#### ìƒˆ ë°©ì‹ (Stream ê¸°ë°˜)
```python
def crawl_with_stream(event_bus):
    for article in crawl():
        # 1. ê¸°ë³¸ ì •ë³´ë§Œ DB ì €ì¥
        article_id = save_basic_info(article)

        # 2. Streamì— ë°œí–‰ (Analyzerê°€ ì²˜ë¦¬)
        event_bus.publish_to_stream('stream:new_articles', {
            'article_id': article_id
        })
```

**ì¥ì :**
- í¬ë¡¤ë§ ì†ë„ í–¥ìƒ (ë¶„ì„ ëŒ€ê¸° ë¶ˆí•„ìš”)
- í¬ë¡¤ë§ê³¼ ë¶„ì„ ë…ë¦½ì  í™•ì¥

---

### 4. Analyzer Consumer (D5, D6)

**íŒŒì¼:** `app/analyzer_consumer.py`

Streamì—ì„œ ê¸°ì‚¬ë¥¼ ë°›ì•„ ë¶„ì„:

```python
class AnalyzerConsumer:
    def process_article(self, message):
        article_id = message['article_id']

        # DBì—ì„œ article ì¡°íšŒ
        article = db.query(NewsArticle).get(article_id)

        # ê°ì„± ë¶„ì„ & í‹°ì»¤ ì¶”ì¶œ
        sentiment = sentiment_analyzer.analyze(article.text)
        tickers = ticker_extractor.extract(article.text)

        # DB ì—…ë°ì´íŠ¸ (D6: DB Writer)
        article.sentiment_score = sentiment['score']
        article.save_tickers(tickers)
        db.commit()
```

**Consumer Group ì‚¬ìš©:**
- ì—¬ëŸ¬ Analyzer Worker ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
- ë©”ì‹œì§€ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
- ì‹¤íŒ¨ ì‹œ ì¬ì²˜ë¦¬

---

### 5. Orchestrator (D2)

**íŒŒì¼:** `app/worker.py`

3ê°œì˜ ì‹¤í–‰ ìŠ¤ë ˆë“œ ê´€ë¦¬:

```python
# Main Thread: APScheduler
scheduler.add_job(crawl_all_news, 'interval', hours=1)

# Thread 1: Command Listener
Thread(target=listen_commands).start()

# Thread 2: Analyzer Consumer
Thread(target=consume_stream).start()
```

---

## ë°ì´í„° í”Œë¡œìš°

### ìë™ í¬ë¡¤ë§ (APScheduler)
```
1. APScheduler â†’ crawl_all_news() (ë§¤ 1ì‹œê°„)
2. Crawler â†’ Redis Stream ('stream:new_articles')
3. Analyzer Consumer â†’ ê°ì„± ë¶„ì„ + í‹°ì»¤ ì¶”ì¶œ
4. DB Writer â†’ PostgreSQL/SQLite
```

### ìˆ˜ë™ í¬ë¡¤ë§ (Spring íŠ¸ë¦¬ê±°)
```
1. Spring â†’ Redis Queue ('marketpulse:commands')
2. Command Handler â†’ crawl_with_stream()
3. Crawler â†’ Redis Stream
4. Analyzer Consumer â†’ ë¶„ì„
5. Python â†’ Redis Pub/Sub ('marketpulse:status')
6. Spring â†’ ìƒíƒœ ìˆ˜ì‹  â†’ WebSocket â†’ í”„ë¡ íŠ¸ì—”ë“œ
```

---

## ì‹¤í–‰ ë°©ë²•

### 1. Redis ì‹œì‘
```bash
# Docker
docker run -d -p 6379:6379 redis:7-alpine

# ë˜ëŠ” ë¡œì»¬
redis-server
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env
REDIS_URL=redis://localhost:6379/0
REDIS_QUEUE_NAME=marketpulse:commands
REDIS_STATUS_CHANNEL=marketpulse:status
SCHEDULER_ENABLED=true
QUEUE_ENABLED=true
```

### 3. Worker ì‹¤í–‰
```bash
python -m app.main
```

**ì˜ˆìƒ ì¶œë ¥:**
```
================================================================================
MarketPulse Background Worker Starting (Stream Architecture)
Database: sqlite:///data/marketpulse.db
APScheduler: Enabled
Redis Queue: Enabled
================================================================================

[Thread 1] Starting Command Listener...
[Thread 1] Command Listener started

[Thread 2] Starting Analyzer Consumer...
[Thread 2] Analyzer Consumer started

================================================================================
Background Worker is running...
  - APScheduler: Auto-scheduling tasks
  - Command Listener: Listening on 'marketpulse:commands'
  - Analyzer Consumer: Consuming 'stream:new_articles'
Press Ctrl+C to stop
================================================================================
```

### 4. ìˆ˜ë™ ëª…ë ¹ ë°œì†¡ (Redis CLI)
```bash
# Spring ëŒ€ì‹  Redis CLIë¡œ í…ŒìŠ¤íŠ¸
redis-cli RPUSH marketpulse:commands '{"task_type":"crawl_news","params":{}}'

# ë¡œê·¸ í™•ì¸
tail -f logs/app.log
```

---

## ëª¨ë‹ˆí„°ë§

### Redis Stream í™•ì¸
```bash
# Stream ê¸¸ì´ í™•ì¸
redis-cli XLEN stream:new_articles

# Consumer Group ì •ë³´
redis-cli XINFO GROUPS stream:new_articles

# ë¯¸ì²˜ë¦¬ ë©”ì‹œì§€ í™•ì¸
redis-cli XPENDING stream:new_articles analyzer-group
```

### ìƒíƒœ êµ¬ë… (Spring ì‹œë®¬ë ˆì´ì…˜)
```bash
redis-cli SUBSCRIBE marketpulse:status
```

---

## í™•ì¥ ê°€ëŠ¥ì„±

### ì—¬ëŸ¬ Analyzer Worker ë³‘ë ¬ ì‹¤í–‰
```bash
# Worker 1
python -m app.main

# Worker 2 (ë‹¤ë¥¸ í„°ë¯¸ë„)
python -m app.main
```

**ìë™ ë¶„ì‚° ì²˜ë¦¬:**
- Redis Consumer Groupì´ ë©”ì‹œì§€ë¥¼ ìë™ ë¶„ë°°
- ê° Workerê°€ ë‹¤ë¥¸ ê¸°ì‚¬ ì²˜ë¦¬
- ì²˜ë¦¬ëŸ‰ 2ë°° ì¦ê°€

### Kubernetes ë°°í¬
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: marketpulse-worker
spec:
  replicas: 3  # 3ê°œì˜ Worker ì‹¤í–‰
  template:
    spec:
      containers:
      - name: worker
        image: marketpulse-python:latest
        command: ["python", "-m", "app.main"]
```

---

## ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ì˜ ì°¨ì´

| í•­ëª© | ê¸°ì¡´ (Threading) | ìƒˆ ì•„í‚¤í…ì²˜ (Stream) |
|------|------------------|---------------------|
| Crawler-Analyzer ì—°ê²° | ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ | Redis Stream |
| í™•ì¥ì„± | ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ì œí•œ | ì—¬ëŸ¬ Worker ê°€ëŠ¥ |
| ì‹¤íŒ¨ ì²˜ë¦¬ | ì¬ì‹œë„ ì—†ìŒ | Stream ACK ê¸°ë°˜ ì¬ì²˜ë¦¬ |
| Spring ìƒíƒœ ì „ì†¡ | ì—†ìŒ | Pub/Sub ì‹¤ì‹œê°„ ì „ì†¡ |
| ëª¨ë‹ˆí„°ë§ | ë¡œê·¸ë§Œ | Redis ëª…ë ¹ì–´ë¡œ í™•ì¸ ê°€ëŠ¥ |

---

## ë‹¤ìŒ ë‹¨ê³„

### ìš°ì„ ìˆœìœ„ 1: Spring Boot ì—°ë™
- RedisTemplateìœ¼ë¡œ ëª…ë ¹ ë°œí–‰
- MessageListenerë¡œ ìƒíƒœ êµ¬ë…
- WebSocketìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œì— ì „ë‹¬

### ìš°ì„ ìˆœìœ„ 2: ëª¨ë‹ˆí„°ë§
- Grafana + Prometheus
- Redis Stream ë©”íŠ¸ë¦­
- Worker ìƒíƒœ ëŒ€ì‹œë³´ë“œ

### ìš°ì„ ìˆœìœ„ 3: í”„ë¡œë•ì…˜ ë°°í¬
- Systemd Service ì„¤ì •
- Docker Compose í†µí•©
- Kubernetes Deployment

---

## ì°¸ê³  ë¬¸ì„œ

- [Redis Streams ê³µì‹ ë¬¸ì„œ](https://redis.io/docs/data-types/streams/)
- [APScheduler ë¬¸ì„œ](https://apscheduler.readthedocs.io/)
- [Python Threading](https://docs.python.org/3/library/threading.html)
